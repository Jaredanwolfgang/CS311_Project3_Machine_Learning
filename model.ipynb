{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS311 Project 3: Adult Census Income Prediction\n",
    "In this project, I try to implement several models to help predict the income of the test datasets. \n",
    "\n",
    "- Decision Tree\n",
    "- Naive Bayes\n",
    "- Nearest Neighbors Classifiers\n",
    "- Support Vector Machines\n",
    "- Ensemble Models\n",
    "- Neural Networks\n",
    "\n",
    "And try to compare the performance of these models to find the best one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "First, we should load the data and check the missing values. The relevant fields are:\n",
    "\n",
    "From `data/traindata.csv` and `data/testdata.csv`:\n",
    "\n",
    "| Attribute | Description                                       | Type     | \n",
    "|-----------|---------------------------------------------------|----------|\n",
    "| **age** | the working age of each data sample                | Numeric  | \n",
    "| **workclass** | type of work, where there are private, local government, etc. | Character |\n",
    "| **fnlwgt** | the number of observational representatives of a sample in a state | Numeric |\n",
    "| **education** | the level of education of each sample  | Character |\n",
    "| **education_num** | the schooling year of each sample  | Numeric   |\n",
    "| **marital_status** | marital status of each sample  | Character | \n",
    "| **occupation** | the occupation of each sample | Character |\n",
    "| **relationship** | the family relationship of each sample | Character |\n",
    "| **race** | the race of each sample | Character |\n",
    "| **gender** | the sex of each sample | Character |\n",
    "| **capital_gain** | a capital gain is a profit that results from a disposition of a capital asset, such as stock, bond or real estate, where the amount realised on the disposition exceeds the purchase price | Numeric |\n",
    "| **capital_loss** | capital loss is the difference between a lower selling price and a higher purchase price, resulting in a financial loss for each sample | Numeric |\n",
    "| **hours_per_week** | sample weekly working hours | Numeric |\n",
    "| **native_country** | the country where the sample is from | Character |\n",
    "\n",
    "From `data/trainlabel.txt`:\n",
    "| Attribute | Description                                       | Type     | \n",
    "|-----------|---------------------------------------------------|----------|\n",
    "| **income:** | income, where income is greater than 50K and less than or equal to 50K | Boolean |\n",
    "\n",
    "The preprocessing process will do the following jobs:\n",
    "- Load the data\n",
    "- Categorize every attributes, and map each value to a numeric value\n",
    "- Detect null or missing values (Some places use ? to represent unknow data)\n",
    "- Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T03:51:15.762832Z",
     "start_time": "2024-06-09T03:51:15.721314Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# Use the given data set\n",
    "train_data = pd.read_csv('data/traindata.csv') # Load the train data\n",
    "train_label = pd.read_csv('data/trainlabel.txt', header=None, names=['label']) # Load the data label\n",
    "test_data = pd.read_csv('data/testdata.csv') # Load the test data\n",
    "test_label = pd.read_csv('data/testlabel.txt', header=None, names=['label']) # Load the test data label \n",
    "\n",
    "# Use split to split the data into training and validation sets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# data = pd.read_csv('data/adult.csv')\n",
    "# X = data.drop('income', axis=1)\n",
    "# Y = data['income']\n",
    "# train_data, test_data, train_label, test_label = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After printing the values, we can categorize each attributes. \n",
    "\n",
    "\n",
    "| workclass | assigned values |\n",
    "|-----------|-----------------|\n",
    "| Local-gov |               1 |\n",
    "| Self-emp-inc |            2 |\n",
    "| Self-emp-not-inc |        3 |\n",
    "| Private |                 4 |\n",
    "| State-gov |               5 |\n",
    "| Federal-gov |             6 |\n",
    "| Never-worked |            7 |\n",
    "| Without-pay |             8 |\n",
    "| ? |                       0 |\n",
    "\n",
    "The workclass attribute has 9 unique values, and we map them to 9 different values.\n",
    "\n",
    "| education | assigned values |\n",
    "|-----------|-----------------|\n",
    "| Preschool |               1 |\n",
    "| 1st-4th |                 2 |\n",
    "| 5th-6th |                 3 |\n",
    "| 7th-8th |                 4 |\n",
    "| 9th |                     5 |\n",
    "| 10th |                    6 |\n",
    "| 11th |                    7 |\n",
    "| 12th |                    8 |\n",
    "| HS-grad |                 9 |\n",
    "| Some-college |           10 |\n",
    "| Assoc-voc |              11 |\n",
    "| Assoc-acdm |             12 |\n",
    "| Bachelors |              13 |\n",
    "| Masters |                14 |\n",
    "| Prof-school |            15 |\n",
    "| Doctorate |              16 |\n",
    "\n",
    "The education attribute has 16 unique values, and we map them to 16 different values.\n",
    "\n",
    "| marital_status | assigned values |\n",
    "|----------------|-----------------|\n",
    "| Never-married |                1 |\n",
    "| Married-civ-spouse |           2 |\n",
    "| Married-AF-spouse |            3 |\n",
    "| Married-spouse-absent |        4 |\n",
    "| Separated |                    5 |\n",
    "| Divorced |                     6 |\n",
    "| Widowed |                      7 |\n",
    "\n",
    "The marital_status attribute has 7 unique values, and we map them to 7 different values.\n",
    "\n",
    "| occupation | assigned values |\n",
    "|------------|-----------------|\n",
    "| Adm-clerical |             1 |\n",
    "| Craft-repair |             2 |\n",
    "| Transport-moving |         3 |\n",
    "| Sales |                    4 |\n",
    "| Handlers-cleaners |        5 |\n",
    "| Prof-specialty |           6 |\n",
    "| Machine-op-inspct |        7 |\n",
    "| Tech-support |             8 |\n",
    "| Exec-managerial |          9 |\n",
    "| Farming-fishing |         10 |\n",
    "| Protective-serv |         11 |\n",
    "| Priv-house-serv |         12 |\n",
    "| Armed-Forces |            13 |\n",
    "| Other-service |           14 |\n",
    "| ? |                        0 |\n",
    "\n",
    "The occupation attribute has 14 unique values, and we map them to 14 different values.\n",
    "\n",
    "| relationship | assigned values |\n",
    "|--------------|-----------------|\n",
    "| Unmarried |                  1 |\n",
    "| Not-in-family |              2 |\n",
    "| Husband |                    3 |\n",
    "| Wife |                       4 |\n",
    "| Own-child |                  5 |\n",
    "| Other-relative |             6 |\n",
    "\n",
    "The relationship attribute has 6 unique values, and we map them to 6 different values\n",
    "\n",
    "| race | assigned values |\n",
    "|------|-----------------|\n",
    "| White |              1 |\n",
    "| Asian-Pac-Islander | 2 |\n",
    "| Black |              3 |\n",
    "| Amer-Indian-Eskimo | 4 |\n",
    "| Other |              5 |\n",
    "\n",
    "The race attribute has 5 unique values, and we map them to 5 different\n",
    "\n",
    "| sex | assigned values |\n",
    "|-----|-----------------|\n",
    "| Male |              0 |\n",
    "| Female |            1 |\n",
    "\n",
    "The sex attribute has 2 unique values, and we map them to 2 different values\n",
    "\n",
    "| native_country        | assigned values |\n",
    "|-----------------------|-----------------|\n",
    "| ?                     | 0               |\n",
    "| Cambodia              | 1               |\n",
    "| Canada                | 2               |\n",
    "| China                 | 3               |\n",
    "| Columbia              | 4               |\n",
    "| Cuba                  | 5               |\n",
    "| Dominican-Republic    | 6               |\n",
    "| Ecuador               | 7               |\n",
    "| El-Salvador           | 8               |\n",
    "| England               | 9               |\n",
    "| France                | 10              |\n",
    "| Germany               | 11              |\n",
    "| Greece                | 12              |\n",
    "| Guatemala             | 13              |\n",
    "| Haiti                 | 14              |\n",
    "| Holand-Netherlands    | 15              |\n",
    "| Honduras              | 16              |\n",
    "| Hong                  | 17              |\n",
    "| Hungary               | 18              |\n",
    "| India                 | 19              |\n",
    "| Iran                  | 20              |\n",
    "| Ireland               | 21              |\n",
    "| Italy                 | 22              |\n",
    "| Jamaica               | 23              |\n",
    "| Japan                 | 24              |\n",
    "| Laos                  | 25              |\n",
    "| Mexico                | 26              |\n",
    "| Nicaragua             | 27              |\n",
    "| Outlying-US(Guam-USVI-etc) | 28         |\n",
    "| Peru                  | 29              |\n",
    "| Philippines           | 30              |\n",
    "| Poland                | 31              |\n",
    "| Portugal              | 32              |\n",
    "| Puerto-Rico           | 33              |\n",
    "| Scotland              | 34              |\n",
    "| South                 | 35              |\n",
    "| Taiwan                | 36              |\n",
    "| Thailand              | 37              |\n",
    "| Trinadad&Tobago       | 38              |\n",
    "| United-States         | 39              |\n",
    "| Vietnam               | 40              |\n",
    "| Yugoslavia            | 41              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the above assign values, we can map each attribute to a number\n",
    "# Workclass \n",
    "train_data['workclass'] = train_data['workclass'].map({\n",
    "    'Local-gov': 1,\n",
    "    'Self-emp-inc': 2,\n",
    "    'Self-emp-not-inc': 3,\n",
    "    'Private': 4,\n",
    "    'State-gov': 5,\n",
    "    'Federal-gov': 6,\n",
    "    'Never-worked': 7,\n",
    "    'Without-pay': 8,\n",
    "    '?': 0\n",
    "})\n",
    "test_data['workclass'] = test_data['workclass'].map({\n",
    "    'Local-gov': 1,\n",
    "    'Self-emp-inc': 2,\n",
    "    'Self-emp-not-inc': 3,\n",
    "    'Private': 4,\n",
    "    'State-gov': 5,\n",
    "    'Federal-gov': 6,\n",
    "    'Never-worked': 7,\n",
    "    'Without-pay': 8,\n",
    "    '?': 0\n",
    "})\n",
    "# Education\n",
    "train_data['education'] = train_data['education'].map({\n",
    "    'Preschool': 1,\n",
    "    '1st-4th': 2,\n",
    "    '5th-6th': 3,\n",
    "    '7th-8th': 4,\n",
    "    '9th': 5,\n",
    "    '10th': 6,\n",
    "    '11th': 7,\n",
    "    '12th': 8,\n",
    "    'HS-grad': 9,\n",
    "    'Some-college': 10,\n",
    "    'Assoc-voc': 11,\n",
    "    'Assoc-acdm': 12,\n",
    "    'Bachelors': 13,\n",
    "    'Masters': 14,\n",
    "    'Prof-school': 15,\n",
    "    'Doctorate': 16\n",
    "})\n",
    "test_data['education'] = test_data['education'].map({\n",
    "    'Preschool': 1,\n",
    "    '1st-4th': 2,\n",
    "    '5th-6th': 3,\n",
    "    '7th-8th': 4,\n",
    "    '9th': 5,\n",
    "    '10th': 6,\n",
    "    '11th': 7,\n",
    "    '12th': 8,\n",
    "    'HS-grad': 9,\n",
    "    'Some-college': 10,\n",
    "    'Assoc-voc': 11,\n",
    "    'Assoc-acdm': 12,\n",
    "    'Bachelors': 13,\n",
    "    'Masters': 14,\n",
    "    'Prof-school': 15,\n",
    "    'Doctorate': 16\n",
    "})\n",
    "# Marital Status\n",
    "train_data['marital.status'] = train_data['marital.status'].map({\n",
    "    'Never-married': 1,\n",
    "    'Married-civ-spouse': 2,\n",
    "    'Married-AF-spouse': 3,\n",
    "    'Married-spouse-absent': 4,\n",
    "    'Separated': 5,\n",
    "    'Divorced': 6,\n",
    "    'Widowed': 7\n",
    "})\n",
    "test_data['marital.status'] = test_data['marital.status'].map({\n",
    "    'Never-married': 1,\n",
    "    'Married-civ-spouse': 2,\n",
    "    'Married-AF-spouse': 3,\n",
    "    'Married-spouse-absent': 4,\n",
    "    'Separated': 5,\n",
    "    'Divorced': 6,\n",
    "    'Widowed': 7\n",
    "})\n",
    "# Occupation\n",
    "train_data['occupation'] = train_data['occupation'].map({\n",
    "    'Adm-clerical': 1,\n",
    "    'Craft-repair': 2,\n",
    "    'Transport-moving': 3,\n",
    "    'Sales': 4,\n",
    "    'Handlers-cleaners': 5,\n",
    "    'Prof-specialty': 6,\n",
    "    'Machine-op-inspct': 7,\n",
    "    'Tech-support': 8,\n",
    "    'Exec-managerial': 9,\n",
    "    'Farming-fishing': 10,\n",
    "    'Protective-serv': 11,\n",
    "    'Priv-house-serv': 12,\n",
    "    'Armed-Forces': 13,\n",
    "    'Other-service': 14,\n",
    "    '?': 0\n",
    "})\n",
    "test_data['occupation'] = test_data['occupation'].map({\n",
    "    'Adm-clerical': 1,\n",
    "    'Craft-repair': 2,\n",
    "    'Transport-moving': 3,\n",
    "    'Sales': 4,\n",
    "    'Handlers-cleaners': 5,\n",
    "    'Prof-specialty': 6,\n",
    "    'Machine-op-inspct': 7,\n",
    "    'Tech-support': 8,\n",
    "    'Exec-managerial': 9,\n",
    "    'Farming-fishing': 10,\n",
    "    'Protective-serv': 11,\n",
    "    'Priv-house-serv': 12,\n",
    "    'Armed-Forces': 13,\n",
    "    'Other-service': 14,\n",
    "    '?': 0\n",
    "})\n",
    "# Relationship\n",
    "train_data['relationship'] = train_data['relationship'].map({\n",
    "    'Unmarried': 1,\n",
    "    'Not-in-family': 2,\n",
    "    'Husband': 3,\n",
    "    'Wife': 4,\n",
    "    'Own-child': 5,\n",
    "    'Other-relative': 6\n",
    "})\n",
    "test_data['relationship'] = test_data['relationship'].map({\n",
    "    'Unmarried': 1,\n",
    "    'Not-in-family': 2,\n",
    "    'Husband': 3,\n",
    "    'Wife': 4,\n",
    "    'Own-child': 5,\n",
    "    'Other-relative': 6\n",
    "})\n",
    "# Race \n",
    "train_data['race'] = train_data['race'].map({\n",
    "    'White': 1,\n",
    "    'Asian-Pac-Islander': 2,\n",
    "    'Black': 3,\n",
    "    'Amer-Indian-Eskimo': 4,\n",
    "    'Other': 5\n",
    "})\n",
    "test_data['race'] = test_data['race'].map({\n",
    "    'White': 1,\n",
    "    'Asian-Pac-Islander': 2,\n",
    "    'Black': 3,\n",
    "    'Amer-Indian-Eskimo': 4,\n",
    "    'Other': 5\n",
    "})\n",
    "# Sex\n",
    "train_data['sex'] = train_data['sex'].map({\n",
    "    'Male': 0,\n",
    "    'Female': 1\n",
    "})\n",
    "test_data['sex'] = test_data['sex'].map({\n",
    "    'Male': 0,\n",
    "    'Female': 1\n",
    "})\n",
    "# Native Countries\n",
    "train_data['native.country'] = train_data['native.country'].map({\n",
    "    '?': 0,\n",
    "    'Cambodia': 1,\n",
    "    'Canada': 2,\n",
    "    'China': 3,\n",
    "    'Columbia': 4,\n",
    "    'Cuba': 5,\n",
    "    'Dominican-Republic': 6,\n",
    "    'Ecuador': 7,\n",
    "    'El-Salvador': 8,\n",
    "    'England': 9,\n",
    "    'France': 10,\n",
    "    'Germany': 11,\n",
    "    'Greece': 12,\n",
    "    'Guatemala': 13,\n",
    "    'Haiti': 14,\n",
    "    'Holand-Netherlands': 15,\n",
    "    'Honduras': 16,\n",
    "    'Hong': 17,\n",
    "    'Hungary': 18,\n",
    "    'India': 19,\n",
    "    'Iran': 20,\n",
    "    'Ireland': 21,\n",
    "    'Italy': 22,\n",
    "    'Jamaica': 23,\n",
    "    'Japan': 24,\n",
    "    'Laos': 25,\n",
    "    'Mexico': 26,\n",
    "    'Nicaragua': 27,\n",
    "    'Outlying-US(Guam-USVI-etc)': 28,\n",
    "    'Peru': 29,\n",
    "    'Philippines': 30,\n",
    "    'Poland': 31,\n",
    "    'Portugal': 32,\n",
    "    'Puerto-Rico': 33,\n",
    "    'Scotland': 34,\n",
    "    'South': 35,\n",
    "    'Taiwan': 36,\n",
    "    'Thailand': 37,\n",
    "    'Trinadad&Tobago': 38,\n",
    "    'United-States': 39,\n",
    "    'Vietnam': 40,\n",
    "    'Yugoslavia': 41\n",
    "})\n",
    "test_data['native.country'] = test_data['native.country'].map({\n",
    "    '?': 0,\n",
    "    'Cambodia': 1,\n",
    "    'Canada': 2,\n",
    "    'China': 3,\n",
    "    'Columbia': 4,\n",
    "    'Cuba': 5,\n",
    "    'Dominican-Republic': 6,\n",
    "    'Ecuador': 7,\n",
    "    'El-Salvador': 8,\n",
    "    'England': 9,\n",
    "    'France': 10,\n",
    "    'Germany': 11,\n",
    "    'Greece': 12,\n",
    "    'Guatemala': 13,\n",
    "    'Haiti': 14,\n",
    "    'Holand-Netherlands': 15,\n",
    "    'Honduras': 16,\n",
    "    'Hong': 17,\n",
    "    'Hungary': 18,\n",
    "    'India': 19,\n",
    "    'Iran': 20,\n",
    "    'Ireland': 21,\n",
    "    'Italy': 22,\n",
    "    'Jamaica': 23,\n",
    "    'Japan': 24,\n",
    "    'Laos': 25,\n",
    "    'Mexico': 26,\n",
    "    'Nicaragua': 27,\n",
    "    'Outlying-US(Guam-USVI-etc)': 28,\n",
    "    'Peru': 29,\n",
    "    'Philippines': 30,\n",
    "    'Poland': 31,\n",
    "    'Portugal': 32,\n",
    "    'Puerto-Rico': 33,\n",
    "    'Scotland': 34,\n",
    "    'South': 35,\n",
    "    'Taiwan': 36,\n",
    "    'Thailand': 37,\n",
    "    'Trinadad&Tobago': 38,\n",
    "    'United-States': 39,\n",
    "    'Vietnam': 40,\n",
    "    'Yugoslavia': 41\n",
    "})\n",
    "# Labels\n",
    "# train_label = train_label.map({\n",
    "#     '<=50K': 0,\n",
    "#     '>50K': 1\n",
    "# })\n",
    "# test_label = test_label.map({\n",
    "#     '<=50K': 0,\n",
    "#     '>50K': 1\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.values\n",
    "Y_train = train_label.values.flatten()\n",
    "X_test = test_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "The sklearn decision tree package only takes in numerical values, therefore we need to preprocess the data by mapping. The splitting criterion has three choices: `gini`, `entropy` and `log_loss`. Basically, the `gini` criterion is used to measure the impurity of the node, and the `entropy` criterion is used to measure the information gain of the node. The `log_loss` criterion is used to measure the logistic loss of the node. The output trends of using `entropy` and `log_loss` are nearly the same. The `gini` criterion is slightly better than the other two, which can reach its highest accuracy with a depth of 7. (The other requires a max depth of 10) However, for all of them, the accuracy will go down due to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Decision Tree\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m      4\u001b[0m clf \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mDecisionTreeClassifier(\n\u001b[1;32m      5\u001b[0m     criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m     splitter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      7\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/sklearn/tree/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.tree` module includes decision tree-based models for\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mclassification and regression.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDecisionTree\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeRegressor\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/sklearn/tree/_classes.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecate_positional_args\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_criterion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Criterion\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Splitter\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DepthFirstTreeBuilder\n",
      "File \u001b[0;32msklearn/tree/_criterion.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._criterion\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msklearn/tree/_splitter.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._splitter\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msklearn/tree/_tree.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._tree\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/sklearn/neighbors/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kde\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelDensity\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lof\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocalOutlierFactor\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeighborhoodComponentsAnalysis\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VALID_METRICS, VALID_METRICS_SPARSE\n\u001b[1;32m     20\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBallTree\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistanceMetric\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKDTree\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID_METRICS\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     37\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID_METRICS_SPARSE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/sklearn/neighbors/_nca.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, TransformerMixin\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/sklearn/decomposition/__init__.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m     16\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdict_learning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dict_learning\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nmf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NMF, non_negative_factorization  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/sklearn/decomposition/dict_learning.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# mypy error: Module X has no attribute y (typically for C extensions)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _dict_learning  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pep562\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pep562\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _raise_dep_warning_if_not_pytest\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/sklearn/decomposition/_dict_learning.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m randomized_svd, row_norms\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted, _deprecate_positional_args\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lasso, orthogonal_mp_gram, LassoLars, Lars\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_positive_coding\u001b[39m(method, positive):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m positive \u001b[38;5;129;01mand\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124momp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlars\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/sklearn/linear_model/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianRidge, ARDRegression\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_least_angle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Lars, LassoLars, lars_path, lars_path_gram, LarsCV,\n\u001b[1;32m     12\u001b[0m                            LassoLarsCV, LassoLarsIC)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_coordinate_descent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Lasso, ElasticNet, LassoCV, ElasticNetCV,\n\u001b[1;32m     14\u001b[0m                                   lasso_path, enet_path, MultiTaskLasso,\n\u001b[1;32m     15\u001b[0m                                   MultiTaskElasticNet, MultiTaskElasticNetCV,\n\u001b[1;32m     16\u001b[0m                                   MultiTaskLassoCV)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_glm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (PoissonRegressor,\n\u001b[1;32m     18\u001b[0m                    GammaRegressor, TweedieRegressor)\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:34\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecate_positional_args\n\u001b[1;32m     29\u001b[0m SOLVE_TRIANGULAR_ARGS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck_finite\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[1;32m     32\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlars_path\u001b[39m(X, y, Xy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, Gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, alpha_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m---> 34\u001b[0m               method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlar\u001b[39m\u001b[38;5;124m'\u001b[39m, copy_X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, eps\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfinfo(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m)\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m     35\u001b[0m               copy_Gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, return_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m               return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Least Angle Regression or Lasso path using LARS algorithm [1]\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    The optimization objective for the case method='lasso' is::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m Gram \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = tree.DecisionTreeClassifier(\n",
    "    criterion='gini', \n",
    "    splitter='best', \n",
    "    max_depth=10\n",
    ")\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_test = clf.predict(X_test)\n",
    "accuracy = accuracy_score(test_label, Y_test)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACI.pdf'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot Decision Tree Structure\n",
    "import graphviz\n",
    "feature_names = train_data.columns.to_list()\n",
    "target_names = ['<=50K', '>50K']\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                           feature_names=feature_names,  \n",
    "                           class_names=target_names,  \n",
    "                           filled=True, rounded=True) \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"ACI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "| Feature                        | GaussianNB                                  | MultinomialNB                               | ComplementNB                                | BernoulliNB                                |\n",
    "|-------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|\n",
    "| **Use Case**                   | Continuous data                             | Discrete count data (e.g., word counts)     | Imbalanced discrete count data              | Binary/Boolean features                     |\n",
    "| **Assumption**                 | Features follow a Gaussian distribution     | Features follow a multinomial distribution  | Similar to MultinomialNB but for imbalanced data | Features are binary/Boolean                 |\n",
    "| **Parameter Estimation**       | Mean and variance for each feature          | Feature probabilities based on counts       | Feature probabilities adjusted for imbalance | Feature probabilities for binary features   |\n",
    "| **Common Applications**        | Sensor data, real-valued data               | Text classification                         | Text classification with class imbalance    | Text classification with binary features    |\n",
    "| **Handling of Zero Counts**    | Not applicable                              | Smoothing (Laplace or other)                | Smoothing (Laplace or other)                | Smoothing (Laplace or other)                |\n",
    "| **Performance**                | Fast, handles continuous data well          | Fast, effective for text data               | Better for imbalanced text data             | Fast, effective for binary features         |\n",
    "| **Output**                     | Probability estimates                       | Probability estimates                       | Probability estimates                       | Probability estimates                       |\n",
    "| **Pros**                       | Handles continuous data, simple and fast    | Effective for text classification           | Better performance with imbalanced data     | Simple and effective for binary data        |\n",
    "| **Cons**                       | Assumes normal distribution of features     | Not suitable for continuous data            | More complex than MultinomialNB             | Not suitable for non-binary data            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB Accuracy: 0.7958\n",
      "Multinomial NB Accuracy: 0.7833\n",
      "Complement NB Accuracy: 0.7833\n",
      "Bernoulli NB Accuracy: 0.7892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "gnb = GaussianNB()\n",
    "y_test_gnb = gnb.fit(X_train, Y_train).predict(X_test)\n",
    "accuracy_gnb = accuracy_score(test_label, y_test_gnb)\n",
    "print(f'Gaussian NB Accuracy: {accuracy_gnb:.4f}')\n",
    "\n",
    "mtb = MultinomialNB()\n",
    "y_test_mtb = mtb.fit(X_train, Y_train).predict(X_test)\n",
    "accuracy_mtb = accuracy_score(test_label, y_test_mtb)\n",
    "print(f'Multinomial NB Accuracy: {accuracy_mtb:.4f}')\n",
    "\n",
    "cmb = ComplementNB()\n",
    "y_test_cmb = cmb.fit(X_train, Y_train).predict(X_test)\n",
    "accuracy_cmb = accuracy_score(test_label, y_test_cmb)\n",
    "print(f'Complement NB Accuracy: {accuracy_cmb:.4f}')\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "y_test_bnb = bnb.fit(X_train, Y_train).predict(X_test)\n",
    "accuracy_bnb = accuracy_score(test_label, y_test_bnb)\n",
    "print(f'Bernoulli NB Accuracy: {accuracy_bnb:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Classifiers\n",
    "The key of using nearest neighbor classifiers is to find the best k value or the best radius. This will delineate the clustering boundaries. However, in the case of Radius Neighbors Classifier there are outliers if the radius are set too small. In this case, we can only label the outliers, and the radius size is dependent on whether the data is standardized. The KNeighbors Classifier is more stable than the Radius Neighbors Classifier, and the accuracy is higher after standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_nn = scaler.fit_transform(X_train)\n",
    "X_test_nn = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.8330\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=80, \n",
    "    weights='uniform', \n",
    "    algorithm='auto', \n",
    "    leaf_size=30, \n",
    "    p=2, \n",
    "    metric='minkowski', \n",
    "    metric_params=None, \n",
    "    n_jobs=None\n",
    ")\n",
    "knn.fit(X_train_nn, Y_train)\n",
    "y_pred_knn = knn.predict(X_test_nn)\n",
    "\n",
    "accuracy = accuracy_score(test_label, y_pred_knn)\n",
    "print(f'KNN Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    77      1 177550 ...      0     14     39]\n",
      " [    40      2 475322 ...      0     50     39]\n",
      " [    29      3 341672 ...   1564     50     19]\n",
      " ...\n",
      " [    36      4 301614 ...      0     40     39]\n",
      " [    33      0 335625 ...      0     40     39]\n",
      " [    17      4 331552 ...      0     30     39]]\n",
      "[[ 2.82150613 -1.97303461 -0.11476193 ... -0.21468948 -2.14867342\n",
      "   0.29129778]\n",
      " [ 0.10887775 -1.19516526  2.70646888 ... -0.21468948  0.77521209\n",
      "   0.29129778]\n",
      " [-0.69757933 -0.41729592  1.44020644 ...  3.6907932   0.77521209\n",
      "  -2.25814503]\n",
      " ...\n",
      " [-0.18437937  0.36057343  1.06067827 ... -0.21468948 -0.03697833\n",
      "   0.29129778]\n",
      " [-0.40432221 -2.75090395  1.38291435 ... -0.21468948 -0.03697833\n",
      "   0.29129778]\n",
      " [-1.5773507   0.36057343  1.34432484 ... -0.21468948 -0.84916875\n",
      "   0.29129778]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radius Neighbors Accuracy: 0.8106\n"
     ]
    }
   ],
   "source": [
    "rnc = RadiusNeighborsClassifier(\n",
    "    radius=2.25, \n",
    "    weights='uniform', \n",
    "    algorithm='auto', \n",
    "    leaf_size=30, \n",
    "    p=2, \n",
    "    metric='minkowski', \n",
    "    outlier_label=-1, \n",
    "    metric_params=None, \n",
    "    n_jobs=None\n",
    ")\n",
    "rnc.fit(X_train_nn, Y_train)\n",
    "y_pred_rnc = rnc.predict(X_test_nn)\n",
    "\n",
    "accuracy = accuracy_score(test_label, y_pred_rnc)\n",
    "print(f'Radius Neighbors Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END ...........................svc__C=0.1, svc__gamma=1; total time=  14.5s\n",
      "[CV] END ...........................svc__C=0.1, svc__gamma=1; total time=  12.2s\n",
      "[CV] END ...........................svc__C=0.1, svc__gamma=1; total time=  11.7s\n",
      "[CV] END ...........................svc__C=0.1, svc__gamma=1; total time=  11.9s\n",
      "[CV] END ...........................svc__C=0.1, svc__gamma=1; total time=  11.8s\n",
      "[CV] END .........................svc__C=0.1, svc__gamma=0.1; total time=   4.0s\n",
      "[CV] END .........................svc__C=0.1, svc__gamma=0.1; total time=   4.0s\n",
      "[CV] END .........................svc__C=0.1, svc__gamma=0.1; total time=   4.1s\n",
      "[CV] END .........................svc__C=0.1, svc__gamma=0.1; total time=   4.1s\n",
      "[CV] END .........................svc__C=0.1, svc__gamma=0.1; total time=   4.0s\n",
      "[CV] END ........................svc__C=0.1, svc__gamma=0.01; total time=   4.2s\n",
      "[CV] END ........................svc__C=0.1, svc__gamma=0.01; total time=   4.4s\n",
      "[CV] END ........................svc__C=0.1, svc__gamma=0.01; total time=   4.2s\n",
      "[CV] END ........................svc__C=0.1, svc__gamma=0.01; total time=   4.3s\n",
      "[CV] END ........................svc__C=0.1, svc__gamma=0.01; total time=   4.4s\n",
      "[CV] END .......................svc__C=0.1, svc__gamma=0.001; total time=   4.4s\n",
      "[CV] END .......................svc__C=0.1, svc__gamma=0.001; total time=   4.6s\n",
      "[CV] END .......................svc__C=0.1, svc__gamma=0.001; total time=   4.5s\n",
      "[CV] END .......................svc__C=0.1, svc__gamma=0.001; total time=   4.5s\n",
      "[CV] END .......................svc__C=0.1, svc__gamma=0.001; total time=   4.4s\n",
      "[CV] END .............................svc__C=1, svc__gamma=1; total time=  15.4s\n",
      "[CV] END .............................svc__C=1, svc__gamma=1; total time=  15.1s\n",
      "[CV] END .............................svc__C=1, svc__gamma=1; total time=  15.4s\n",
      "[CV] END .............................svc__C=1, svc__gamma=1; total time=  15.4s\n",
      "[CV] END .............................svc__C=1, svc__gamma=1; total time=  15.0s\n",
      "[CV] END ...........................svc__C=1, svc__gamma=0.1; total time=   4.0s\n",
      "[CV] END ...........................svc__C=1, svc__gamma=0.1; total time=   4.0s\n",
      "[CV] END ...........................svc__C=1, svc__gamma=0.1; total time=   4.1s\n",
      "[CV] END ...........................svc__C=1, svc__gamma=0.1; total time=   4.1s\n",
      "[CV] END ...........................svc__C=1, svc__gamma=0.1; total time=   4.1s\n",
      "[CV] END ..........................svc__C=1, svc__gamma=0.01; total time=   3.8s\n",
      "[CV] END ..........................svc__C=1, svc__gamma=0.01; total time=   3.9s\n",
      "[CV] END ..........................svc__C=1, svc__gamma=0.01; total time=   3.9s\n",
      "[CV] END ..........................svc__C=1, svc__gamma=0.01; total time=   3.8s\n",
      "[CV] END ..........................svc__C=1, svc__gamma=0.01; total time=   3.7s\n",
      "[CV] END .........................svc__C=1, svc__gamma=0.001; total time=   4.3s\n",
      "[CV] END .........................svc__C=1, svc__gamma=0.001; total time=   4.4s\n",
      "[CV] END .........................svc__C=1, svc__gamma=0.001; total time=   4.4s\n",
      "[CV] END .........................svc__C=1, svc__gamma=0.001; total time=   4.3s\n",
      "[CV] END .........................svc__C=1, svc__gamma=0.001; total time=   4.4s\n",
      "[CV] END ............................svc__C=10, svc__gamma=1; total time=  18.2s\n",
      "[CV] END ............................svc__C=10, svc__gamma=1; total time=  18.3s\n",
      "[CV] END ............................svc__C=10, svc__gamma=1; total time=  20.2s\n",
      "[CV] END ............................svc__C=10, svc__gamma=1; total time=  18.4s\n",
      "[CV] END ............................svc__C=10, svc__gamma=1; total time=  19.9s\n",
      "[CV] END ..........................svc__C=10, svc__gamma=0.1; total time=   5.3s\n",
      "[CV] END ..........................svc__C=10, svc__gamma=0.1; total time=   5.2s\n",
      "[CV] END ..........................svc__C=10, svc__gamma=0.1; total time=   5.3s\n",
      "[CV] END ..........................svc__C=10, svc__gamma=0.1; total time=   5.3s\n",
      "[CV] END ..........................svc__C=10, svc__gamma=0.1; total time=   5.2s\n",
      "[CV] END .........................svc__C=10, svc__gamma=0.01; total time=   3.9s\n",
      "[CV] END .........................svc__C=10, svc__gamma=0.01; total time=   4.0s\n",
      "[CV] END .........................svc__C=10, svc__gamma=0.01; total time=   4.1s\n",
      "[CV] END .........................svc__C=10, svc__gamma=0.01; total time=   4.0s\n",
      "[CV] END .........................svc__C=10, svc__gamma=0.01; total time=   3.8s\n",
      "[CV] END ........................svc__C=10, svc__gamma=0.001; total time=   4.0s\n",
      "[CV] END ........................svc__C=10, svc__gamma=0.001; total time=   4.1s\n",
      "[CV] END ........................svc__C=10, svc__gamma=0.001; total time=   4.4s\n",
      "[CV] END ........................svc__C=10, svc__gamma=0.001; total time=   4.0s\n",
      "[CV] END ........................svc__C=10, svc__gamma=0.001; total time=   4.0s\n",
      "[CV] END ...........................svc__C=100, svc__gamma=1; total time=  27.3s\n",
      "[CV] END ...........................svc__C=100, svc__gamma=1; total time=  27.2s\n",
      "[CV] END ...........................svc__C=100, svc__gamma=1; total time=  26.8s\n",
      "[CV] END ...........................svc__C=100, svc__gamma=1; total time=  27.1s\n",
      "[CV] END ...........................svc__C=100, svc__gamma=1; total time=  26.6s\n",
      "[CV] END .........................svc__C=100, svc__gamma=0.1; total time=  12.5s\n",
      "[CV] END .........................svc__C=100, svc__gamma=0.1; total time=  12.4s\n",
      "[CV] END .........................svc__C=100, svc__gamma=0.1; total time=  12.3s\n",
      "[CV] END .........................svc__C=100, svc__gamma=0.1; total time=  12.4s\n",
      "[CV] END .........................svc__C=100, svc__gamma=0.1; total time=  11.6s\n",
      "[CV] END ........................svc__C=100, svc__gamma=0.01; total time=   5.7s\n",
      "[CV] END ........................svc__C=100, svc__gamma=0.01; total time=   5.7s\n",
      "[CV] END ........................svc__C=100, svc__gamma=0.01; total time=   5.8s\n",
      "[CV] END ........................svc__C=100, svc__gamma=0.01; total time=   5.8s\n",
      "[CV] END ........................svc__C=100, svc__gamma=0.01; total time=   5.8s\n",
      "[CV] END .......................svc__C=100, svc__gamma=0.001; total time=   4.2s\n",
      "[CV] END .......................svc__C=100, svc__gamma=0.001; total time=   4.2s\n",
      "[CV] END .......................svc__C=100, svc__gamma=0.001; total time=   4.2s\n",
      "[CV] END .......................svc__C=100, svc__gamma=0.001; total time=   4.2s\n",
      "[CV] END .......................svc__C=100, svc__gamma=0.001; total time=   4.2s\n",
      "Best parameters found:  {'svc__C': 1, 'svc__gamma': 0.1}\n",
      "Best estimator:  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('svc', SVC(C=1, gamma=0.1))])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m svc\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m     30\u001b[0m y_pred_svc \u001b[38;5;241m=\u001b[39m svc\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m---> 31\u001b[0m accuracy_svc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m(test_label, y_pred_svc)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVC Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_svc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__gamma': [1, 0.1, 0.01, 0.001],\n",
    "}\n",
    "pipeline = make_pipeline(StandardScaler(), SVC(kernel='rbf'))\n",
    "grid_search = GridSearchCV(pipeline, param_grid, refit=True, verbose=2, cv=5)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best estimator: \", grid_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 0.7589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "svc = SVC(\n",
    "    C=grid_search.best_params_['svc__C'], \n",
    "    kernel='rbf', \n",
    "    degree=3, \n",
    "    gamma=grid_search.best_params_['svc__gamma'], \n",
    "    coef0=0.0, \n",
    "    shrinking=True, \n",
    "    probability=False, \n",
    "    tol=0.001, \n",
    "    cache_size=200, \n",
    "    class_weight=None\n",
    ")\n",
    "svc.fit(X_train, Y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "accuracy_svc = accuracy_score(test_label, y_pred_svc)\n",
    "print(f'SVC Accuracy: {accuracy_svc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 0.7589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "gbdt = HistGradientBoostingClassifier(\n",
    "    min_samples_leaf=1,\n",
    "    max_depth=2,\n",
    "    learning_rate=1,\n",
    "    max_iter=1\n",
    ").fit(X_train, Y_train)\n",
    "gbdt.predict(X_test)\n",
    "accuracy_gbdt = accuracy_score(test_label, y_pred_svc)\n",
    "print(f'SVC Accuracy: {accuracy_gbdt:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 0.7589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(\n",
    "    n_estimators=100, \n",
    "    learning_rate=1.0,\n",
    "    max_depth=1, \n",
    "    random_state=0\n",
    ").fit(X_train, Y_train)\n",
    "gbc.predict(X_test)\n",
    "accuracy_gbc = accuracy_score(test_label, y_pred_svc)\n",
    "print(f'SVC Accuracy: {accuracy_gbc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 0.7589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "rfc = RandomForestClassifier().fit(X_train, Y_train)\n",
    "y_pred_rfc = rfc.predict(X_test)\n",
    "accuracy_rfc = accuracy_score(test_label, y_pred_rfc)\n",
    "print(f'RFC Accuracy: {accuracy_rfc:.4f}')\n",
    "print(classification_report(test_label, y_pred_rfc))\n",
    "print(sns.heatmap(confusion_matrix(test_label, y_pred_rfc), annot=True, fmt='d'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "We are using the PyCaret to help us choose the according model. A typical workflow in Pycaret consist of the following steps:\n",
    "- Setup\n",
    "- Compare Models\n",
    "- Analyze Model\n",
    "- Predict\n",
    "- Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'version_' from partially initialized module 'pycaret' (most likely due to a circular import) (/home/ubuntu/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/pycaret/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pycaret\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/pycaret/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/pycaret/utils/__init__.py:11\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/pycaret/utils/__init__.py:2\u001b[0m, in \u001b[0;36mversion\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mversion\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version_\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m version_\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'version_' from partially initialized module 'pycaret' (most likely due to a circular import) (/home/ubuntu/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/pycaret/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pycaret\n",
    "pycaret.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ALL_ALLOWED_ENGINES' from 'pycaret.containers.models.classification' (/home/ubuntu/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/pycaret/containers/models/classification.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassificationExperiment\n\u001b[1;32m      2\u001b[0m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_label\n\u001b[1;32m      3\u001b[0m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_label\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/pycaret/classification/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     add_metric,\n\u001b[1;32m      3\u001b[0m     automl,\n\u001b[1;32m      4\u001b[0m     blend_models,\n\u001b[1;32m      5\u001b[0m     calibrate_model,\n\u001b[1;32m      6\u001b[0m     check_drift,\n\u001b[1;32m      7\u001b[0m     check_fairness,\n\u001b[1;32m      8\u001b[0m     compare_models,\n\u001b[1;32m      9\u001b[0m     convert_model,\n\u001b[1;32m     10\u001b[0m     create_api,\n\u001b[1;32m     11\u001b[0m     create_app,\n\u001b[1;32m     12\u001b[0m     create_docker,\n\u001b[1;32m     13\u001b[0m     create_model,\n\u001b[1;32m     14\u001b[0m     dashboard,\n\u001b[1;32m     15\u001b[0m     deploy_model,\n\u001b[1;32m     16\u001b[0m     ensemble_model,\n\u001b[1;32m     17\u001b[0m     evaluate_model,\n\u001b[1;32m     18\u001b[0m     finalize_model,\n\u001b[1;32m     19\u001b[0m     get_allowed_engines,\n\u001b[1;32m     20\u001b[0m     get_config,\n\u001b[1;32m     21\u001b[0m     get_current_experiment,\n\u001b[1;32m     22\u001b[0m     get_engine,\n\u001b[1;32m     23\u001b[0m     get_leaderboard,\n\u001b[1;32m     24\u001b[0m     get_logs,\n\u001b[1;32m     25\u001b[0m     get_metrics,\n\u001b[1;32m     26\u001b[0m     interpret_model,\n\u001b[1;32m     27\u001b[0m     load_experiment,\n\u001b[1;32m     28\u001b[0m     load_model,\n\u001b[1;32m     29\u001b[0m     models,\n\u001b[1;32m     30\u001b[0m     optimize_threshold,\n\u001b[1;32m     31\u001b[0m     plot_model,\n\u001b[1;32m     32\u001b[0m     predict_model,\n\u001b[1;32m     33\u001b[0m     pull,\n\u001b[1;32m     34\u001b[0m     remove_metric,\n\u001b[1;32m     35\u001b[0m     save_experiment,\n\u001b[1;32m     36\u001b[0m     save_model,\n\u001b[1;32m     37\u001b[0m     set_config,\n\u001b[1;32m     38\u001b[0m     set_current_experiment,\n\u001b[1;32m     39\u001b[0m     setup,\n\u001b[1;32m     40\u001b[0m     stack_models,\n\u001b[1;32m     41\u001b[0m     tune_model,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassificationExperiment\n\u001b[1;32m     45\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassificationExperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_drift\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/pycaret/classification/functional.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Memory\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClassificationExperiment\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelBackend\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_logger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLogger\n",
      "File \u001b[0;32m~/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/pycaret/classification/oop.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shgo\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_all_metric_containers\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     ALL_ALLOWED_ENGINES,\n\u001b[1;32m     19\u001b[0m     get_all_model_containers,\n\u001b[1;32m     20\u001b[0m     get_container_default_engines,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CommonDisplay\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_logger\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ALL_ALLOWED_ENGINES' from 'pycaret.containers.models.classification' (/home/ubuntu/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/pycaret/containers/models/classification.py)"
     ]
    }
   ],
   "source": [
    "from pycaret.classification import ClassificationExperiment\n",
    "train_data['label'] = train_label\n",
    "test_data['label'] = test_label\n",
    "exp = ClassificationExperiment()\n",
    "exp.setup(data = train_data, target = 'label', session_id=123, log_experiment=True, experiment_name='income')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
