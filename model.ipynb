{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS311 Project 3: Adult Census Income Prediction\n",
    "In this project, I try to implement several models to help predict the income of the test datasets. \n",
    "\n",
    "- Decision Tree\n",
    "- Naive Bayes\n",
    "- Nearest Neighbors Classifiers\n",
    "- Support Vector Machines\n",
    "- Ensemble Models\n",
    "- Neural Networks\n",
    "\n",
    "And try to compare the performance of these models to find the best one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "First, we should load the data and check the missing values. The relevant fields are:\n",
    "\n",
    "From `data/traindata.csv` and `data/testdata.csv`:\n",
    "\n",
    "| Attribute | Description                                       | Type     | \n",
    "|-----------|---------------------------------------------------|----------|\n",
    "| **age** | the working age of each data sample                | Numeric  | \n",
    "| **workclass** | type of work, where there are private, local government, etc. | Character |\n",
    "| **fnlwgt** | the number of observational representatives of a sample in a state | Numeric |\n",
    "| **education** | the level of education of each sample  | Character |\n",
    "| **education_num** | the schooling year of each sample  | Numeric   |\n",
    "| **marital_status** | marital status of each sample  | Character | \n",
    "| **occupation** | the occupation of each sample | Character |\n",
    "| **relationship** | the family relationship of each sample | Character |\n",
    "| **race** | the race of each sample | Character |\n",
    "| **gender** | the sex of each sample | Character |\n",
    "| **capital_gain** | a capital gain is a profit that results from a disposition of a capital asset, such as stock, bond or real estate, where the amount realised on the disposition exceeds the purchase price | Numeric |\n",
    "| **capital_loss** | capital loss is the difference between a lower selling price and a higher purchase price, resulting in a financial loss for each sample | Numeric |\n",
    "| **hours_per_week** | sample weekly working hours | Numeric |\n",
    "| **native_country** | the country where the sample is from | Character |\n",
    "\n",
    "From `data/trainlabel.txt`:\n",
    "| Attribute | Description                                       | Type     | \n",
    "|-----------|---------------------------------------------------|----------|\n",
    "| **income:** | income, where income is greater than 50K and less than or equal to 50K | Boolean |\n",
    "\n",
    "The preprocessing process will do the following jobs:\n",
    "- Load the data\n",
    "- Categorize every attributes, and map each value to a numeric value\n",
    "- Detect null or missing values (Some places use ? to represent unknow data)\n",
    "- Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# Use the given data set\n",
    "# train_data = pd.read_csv('data/traindata.csv') # Load the train data\n",
    "# train_labels = pd.read_csv('data/trainlabel.txt', header=None, names=['label']) # Load the data label\n",
    "# test_data = pd.read_csv('data/testdata.csv') # Load the test data\n",
    "\n",
    "# Use split to split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('data/adult.csv')\n",
    "X = data.drop('income', axis=1)\n",
    "Y = data['income']\n",
    "train_data, test_data, train_label, test_label = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After printing the values, we can categorize each attributes. \n",
    "\n",
    "\n",
    "| workclass | assigned values |\n",
    "|-----------|-----------------|\n",
    "| Local-gov |               1 |\n",
    "| Self-emp-inc |            2 |\n",
    "| Self-emp-not-inc |        3 |\n",
    "| Private |                 4 |\n",
    "| State-gov |               5 |\n",
    "| Federal-gov |             6 |\n",
    "| Never-worked |            7 |\n",
    "| Without-pay |             8 |\n",
    "| ? |                       0 |\n",
    "\n",
    "The workclass attribute has 9 unique values, and we map them to 9 different values.\n",
    "\n",
    "| education | assigned values |\n",
    "|-----------|-----------------|\n",
    "| Preschool |               1 |\n",
    "| 1st-4th |                 2 |\n",
    "| 5th-6th |                 3 |\n",
    "| 7th-8th |                 4 |\n",
    "| 9th |                     5 |\n",
    "| 10th |                    6 |\n",
    "| 11th |                    7 |\n",
    "| 12th |                    8 |\n",
    "| HS-grad |                 9 |\n",
    "| Some-college |           10 |\n",
    "| Assoc-voc |              11 |\n",
    "| Assoc-acdm |             12 |\n",
    "| Bachelors |              13 |\n",
    "| Masters |                14 |\n",
    "| Prof-school |            15 |\n",
    "| Doctorate |              16 |\n",
    "\n",
    "The education attribute has 16 unique values, and we map them to 16 different values.\n",
    "\n",
    "| marital_status | assigned values |\n",
    "|----------------|-----------------|\n",
    "| Never-married |                1 |\n",
    "| Married-civ-spouse |           2 |\n",
    "| Married-AF-spouse |            3 |\n",
    "| Married-spouse-absent |        4 |\n",
    "| Separated |                    5 |\n",
    "| Divorced |                     6 |\n",
    "| Widowed |                      7 |\n",
    "\n",
    "The marital_status attribute has 7 unique values, and we map them to 7 different values.\n",
    "\n",
    "| occupation | assigned values |\n",
    "|------------|-----------------|\n",
    "| Adm-clerical |             1 |\n",
    "| Craft-repair |             2 |\n",
    "| Transport-moving |         3 |\n",
    "| Sales |                    4 |\n",
    "| Handlers-cleaners |        5 |\n",
    "| Prof-specialty |           6 |\n",
    "| Machine-op-inspct |        7 |\n",
    "| Tech-support |             8 |\n",
    "| Exec-managerial |          9 |\n",
    "| Farming-fishing |         10 |\n",
    "| Protective-serv |         11 |\n",
    "| Priv-house-serv |         12 |\n",
    "| Armed-Forces |            13 |\n",
    "| Other-service |           14 |\n",
    "| ? |                        0 |\n",
    "\n",
    "The occupation attribute has 14 unique values, and we map them to 14 different values.\n",
    "\n",
    "| relationship | assigned values |\n",
    "|--------------|-----------------|\n",
    "| Unmarried |                  1 |\n",
    "| Not-in-family |              2 |\n",
    "| Husband |                    3 |\n",
    "| Wife |                       4 |\n",
    "| Own-child |                  5 |\n",
    "| Other-relative |             6 |\n",
    "\n",
    "The relationship attribute has 6 unique values, and we map them to 6 different values\n",
    "\n",
    "| race | assigned values |\n",
    "|------|-----------------|\n",
    "| White |              1 |\n",
    "| Asian-Pac-Islander | 2 |\n",
    "| Black |              3 |\n",
    "| Amer-Indian-Eskimo | 4 |\n",
    "| Other |              5 |\n",
    "\n",
    "The race attribute has 5 unique values, and we map them to 5 different\n",
    "\n",
    "| sex | assigned values |\n",
    "|-----|-----------------|\n",
    "| Male |              0 |\n",
    "| Female |            1 |\n",
    "\n",
    "The sex attribute has 2 unique values, and we map them to 2 different values\n",
    "\n",
    "| native_country        | assigned values |\n",
    "|-----------------------|-----------------|\n",
    "| ?                     | 0               |\n",
    "| Cambodia              | 1               |\n",
    "| Canada                | 2               |\n",
    "| China                 | 3               |\n",
    "| Columbia              | 4               |\n",
    "| Cuba                  | 5               |\n",
    "| Dominican-Republic    | 6               |\n",
    "| Ecuador               | 7               |\n",
    "| El-Salvador           | 8               |\n",
    "| England               | 9               |\n",
    "| France                | 10              |\n",
    "| Germany               | 11              |\n",
    "| Greece                | 12              |\n",
    "| Guatemala             | 13              |\n",
    "| Haiti                 | 14              |\n",
    "| Holand-Netherlands    | 15              |\n",
    "| Honduras              | 16              |\n",
    "| Hong                  | 17              |\n",
    "| Hungary               | 18              |\n",
    "| India                 | 19              |\n",
    "| Iran                  | 20              |\n",
    "| Ireland               | 21              |\n",
    "| Italy                 | 22              |\n",
    "| Jamaica               | 23              |\n",
    "| Japan                 | 24              |\n",
    "| Laos                  | 25              |\n",
    "| Mexico                | 26              |\n",
    "| Nicaragua             | 27              |\n",
    "| Outlying-US(Guam-USVI-etc) | 28         |\n",
    "| Peru                  | 29              |\n",
    "| Philippines           | 30              |\n",
    "| Poland                | 31              |\n",
    "| Portugal              | 32              |\n",
    "| Puerto-Rico           | 33              |\n",
    "| Scotland              | 34              |\n",
    "| South                 | 35              |\n",
    "| Taiwan                | 36              |\n",
    "| Thailand              | 37              |\n",
    "| Trinadad&Tobago       | 38              |\n",
    "| United-States         | 39              |\n",
    "| Vietnam               | 40              |\n",
    "| Yugoslavia            | 41              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the above assign values, we can map each attribute to a number\n",
    "# Workclass \n",
    "train_data['workclass'] = train_data['workclass'].map({\n",
    "    'Local-gov': 1,\n",
    "    'Self-emp-inc': 2,\n",
    "    'Self-emp-not-inc': 3,\n",
    "    'Private': 4,\n",
    "    'State-gov': 5,\n",
    "    'Federal-gov': 6,\n",
    "    'Never-worked': 7,\n",
    "    'Without-pay': 8,\n",
    "    '?': 0\n",
    "})\n",
    "test_data['workclass'] = test_data['workclass'].map({\n",
    "    'Local-gov': 1,\n",
    "    'Self-emp-inc': 2,\n",
    "    'Self-emp-not-inc': 3,\n",
    "    'Private': 4,\n",
    "    'State-gov': 5,\n",
    "    'Federal-gov': 6,\n",
    "    'Never-worked': 7,\n",
    "    'Without-pay': 8,\n",
    "    '?': 0\n",
    "})\n",
    "# Education\n",
    "train_data['education'] = train_data['education'].map({\n",
    "    'Preschool': 1,\n",
    "    '1st-4th': 2,\n",
    "    '5th-6th': 3,\n",
    "    '7th-8th': 4,\n",
    "    '9th': 5,\n",
    "    '10th': 6,\n",
    "    '11th': 7,\n",
    "    '12th': 8,\n",
    "    'HS-grad': 9,\n",
    "    'Some-college': 10,\n",
    "    'Assoc-voc': 11,\n",
    "    'Assoc-acdm': 12,\n",
    "    'Bachelors': 13,\n",
    "    'Masters': 14,\n",
    "    'Prof-school': 15,\n",
    "    'Doctorate': 16\n",
    "})\n",
    "test_data['education'] = test_data['education'].map({\n",
    "    'Preschool': 1,\n",
    "    '1st-4th': 2,\n",
    "    '5th-6th': 3,\n",
    "    '7th-8th': 4,\n",
    "    '9th': 5,\n",
    "    '10th': 6,\n",
    "    '11th': 7,\n",
    "    '12th': 8,\n",
    "    'HS-grad': 9,\n",
    "    'Some-college': 10,\n",
    "    'Assoc-voc': 11,\n",
    "    'Assoc-acdm': 12,\n",
    "    'Bachelors': 13,\n",
    "    'Masters': 14,\n",
    "    'Prof-school': 15,\n",
    "    'Doctorate': 16\n",
    "})\n",
    "# Marital Status\n",
    "train_data['marital.status'] = train_data['marital.status'].map({\n",
    "    'Never-married': 1,\n",
    "    'Married-civ-spouse': 2,\n",
    "    'Married-AF-spouse': 3,\n",
    "    'Married-spouse-absent': 4,\n",
    "    'Separated': 5,\n",
    "    'Divorced': 6,\n",
    "    'Widowed': 7\n",
    "})\n",
    "test_data['marital.status'] = test_data['marital.status'].map({\n",
    "    'Never-married': 1,\n",
    "    'Married-civ-spouse': 2,\n",
    "    'Married-AF-spouse': 3,\n",
    "    'Married-spouse-absent': 4,\n",
    "    'Separated': 5,\n",
    "    'Divorced': 6,\n",
    "    'Widowed': 7\n",
    "})\n",
    "# Occupation\n",
    "train_data['occupation'] = train_data['occupation'].map({\n",
    "    'Adm-clerical': 1,\n",
    "    'Craft-repair': 2,\n",
    "    'Transport-moving': 3,\n",
    "    'Sales': 4,\n",
    "    'Handlers-cleaners': 5,\n",
    "    'Prof-specialty': 6,\n",
    "    'Machine-op-inspct': 7,\n",
    "    'Tech-support': 8,\n",
    "    'Exec-managerial': 9,\n",
    "    'Farming-fishing': 10,\n",
    "    'Protective-serv': 11,\n",
    "    'Priv-house-serv': 12,\n",
    "    'Armed-Forces': 13,\n",
    "    'Other-service': 14,\n",
    "    '?': 0\n",
    "})\n",
    "test_data['occupation'] = test_data['occupation'].map({\n",
    "    'Adm-clerical': 1,\n",
    "    'Craft-repair': 2,\n",
    "    'Transport-moving': 3,\n",
    "    'Sales': 4,\n",
    "    'Handlers-cleaners': 5,\n",
    "    'Prof-specialty': 6,\n",
    "    'Machine-op-inspct': 7,\n",
    "    'Tech-support': 8,\n",
    "    'Exec-managerial': 9,\n",
    "    'Farming-fishing': 10,\n",
    "    'Protective-serv': 11,\n",
    "    'Priv-house-serv': 12,\n",
    "    'Armed-Forces': 13,\n",
    "    'Other-service': 14,\n",
    "    '?': 0\n",
    "})\n",
    "# Relationship\n",
    "train_data['relationship'] = train_data['relationship'].map({\n",
    "    'Unmarried': 1,\n",
    "    'Not-in-family': 2,\n",
    "    'Husband': 3,\n",
    "    'Wife': 4,\n",
    "    'Own-child': 5,\n",
    "    'Other-relative': 6\n",
    "})\n",
    "test_data['relationship'] = test_data['relationship'].map({\n",
    "    'Unmarried': 1,\n",
    "    'Not-in-family': 2,\n",
    "    'Husband': 3,\n",
    "    'Wife': 4,\n",
    "    'Own-child': 5,\n",
    "    'Other-relative': 6\n",
    "})\n",
    "# Race \n",
    "train_data['race'] = train_data['race'].map({\n",
    "    'White': 1,\n",
    "    'Asian-Pac-Islander': 2,\n",
    "    'Black': 3,\n",
    "    'Amer-Indian-Eskimo': 4,\n",
    "    'Other': 5\n",
    "})\n",
    "test_data['race'] = test_data['race'].map({\n",
    "    'White': 1,\n",
    "    'Asian-Pac-Islander': 2,\n",
    "    'Black': 3,\n",
    "    'Amer-Indian-Eskimo': 4,\n",
    "    'Other': 5\n",
    "})\n",
    "# Sex\n",
    "train_data['sex'] = train_data['sex'].map({\n",
    "    'Male': 0,\n",
    "    'Female': 1\n",
    "})\n",
    "test_data['sex'] = test_data['sex'].map({\n",
    "    'Male': 0,\n",
    "    'Female': 1\n",
    "})\n",
    "# Native Countries\n",
    "train_data['native.country'] = train_data['native.country'].map({\n",
    "    '?': 0,\n",
    "    'Cambodia': 1,\n",
    "    'Canada': 2,\n",
    "    'China': 3,\n",
    "    'Columbia': 4,\n",
    "    'Cuba': 5,\n",
    "    'Dominican-Republic': 6,\n",
    "    'Ecuador': 7,\n",
    "    'El-Salvador': 8,\n",
    "    'England': 9,\n",
    "    'France': 10,\n",
    "    'Germany': 11,\n",
    "    'Greece': 12,\n",
    "    'Guatemala': 13,\n",
    "    'Haiti': 14,\n",
    "    'Holand-Netherlands': 15,\n",
    "    'Honduras': 16,\n",
    "    'Hong': 17,\n",
    "    'Hungary': 18,\n",
    "    'India': 19,\n",
    "    'Iran': 20,\n",
    "    'Ireland': 21,\n",
    "    'Italy': 22,\n",
    "    'Jamaica': 23,\n",
    "    'Japan': 24,\n",
    "    'Laos': 25,\n",
    "    'Mexico': 26,\n",
    "    'Nicaragua': 27,\n",
    "    'Outlying-US(Guam-USVI-etc)': 28,\n",
    "    'Peru': 29,\n",
    "    'Philippines': 30,\n",
    "    'Poland': 31,\n",
    "    'Portugal': 32,\n",
    "    'Puerto-Rico': 33,\n",
    "    'Scotland': 34,\n",
    "    'South': 35,\n",
    "    'Taiwan': 36,\n",
    "    'Thailand': 37,\n",
    "    'Trinadad&Tobago': 38,\n",
    "    'United-States': 39,\n",
    "    'Vietnam': 40,\n",
    "    'Yugoslavia': 41\n",
    "})\n",
    "test_data['native.country'] = test_data['native.country'].map({\n",
    "    '?': 0,\n",
    "    'Cambodia': 1,\n",
    "    'Canada': 2,\n",
    "    'China': 3,\n",
    "    'Columbia': 4,\n",
    "    'Cuba': 5,\n",
    "    'Dominican-Republic': 6,\n",
    "    'Ecuador': 7,\n",
    "    'El-Salvador': 8,\n",
    "    'England': 9,\n",
    "    'France': 10,\n",
    "    'Germany': 11,\n",
    "    'Greece': 12,\n",
    "    'Guatemala': 13,\n",
    "    'Haiti': 14,\n",
    "    'Holand-Netherlands': 15,\n",
    "    'Honduras': 16,\n",
    "    'Hong': 17,\n",
    "    'Hungary': 18,\n",
    "    'India': 19,\n",
    "    'Iran': 20,\n",
    "    'Ireland': 21,\n",
    "    'Italy': 22,\n",
    "    'Jamaica': 23,\n",
    "    'Japan': 24,\n",
    "    'Laos': 25,\n",
    "    'Mexico': 26,\n",
    "    'Nicaragua': 27,\n",
    "    'Outlying-US(Guam-USVI-etc)': 28,\n",
    "    'Peru': 29,\n",
    "    'Philippines': 30,\n",
    "    'Poland': 31,\n",
    "    'Portugal': 32,\n",
    "    'Puerto-Rico': 33,\n",
    "    'Scotland': 34,\n",
    "    'South': 35,\n",
    "    'Taiwan': 36,\n",
    "    'Thailand': 37,\n",
    "    'Trinadad&Tobago': 38,\n",
    "    'United-States': 39,\n",
    "    'Vietnam': 40,\n",
    "    'Yugoslavia': 41\n",
    "})\n",
    "# Labels\n",
    "train_label = train_label.map({\n",
    "    '<=50K': 0,\n",
    "    '>50K': 1\n",
    "})\n",
    "test_label = test_label.map({\n",
    "    '<=50K': 0,\n",
    "    '>50K': 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.values\n",
    "Y_train = train_label.values.flatten()\n",
    "X_test = test_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "The sklearn decision tree package only takes in numerical values, therefore we need to preprocess the data by mapping. The splitting criterion has three choices: `gini`, `entropy` and `log_loss`. Basically, the `gini` criterion is used to measure the impurity of the node, and the `entropy` criterion is used to measure the information gain of the node. The `log_loss` criterion is used to measure the logistic loss of the node. The output trends of using `entropy` and `log_loss` are nearly the same. The `gini` criterion is slightly better than the other two, which can reach its highest accuracy with a depth of 7. (The other requires a max depth of 10) However, for all of them, the accuracy will go down due to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8452\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', \n",
    "    splitter='best', \n",
    "    max_depth=4\n",
    ")\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_test = clf.predict(X_test)\n",
    "accuracy = accuracy_score(test_label, Y_test)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACI.pdf'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot Decision Tree Structure\n",
    "import graphviz\n",
    "feature_names = train_data.columns.to_list()\n",
    "target_names = ['<=50K', '>50K']\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                           feature_names=feature_names,  \n",
    "                           class_names=target_names,  \n",
    "                           filled=True, rounded=True) \n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"ACI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "| Feature                        | GaussianNB                                  | MultinomialNB                               | ComplementNB                                | BernoulliNB                                |\n",
    "|-------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|\n",
    "| **Use Case**                   | Continuous data                             | Discrete count data (e.g., word counts)     | Imbalanced discrete count data              | Binary/Boolean features                     |\n",
    "| **Assumption**                 | Features follow a Gaussian distribution     | Features follow a multinomial distribution  | Similar to MultinomialNB but for imbalanced data | Features are binary/Boolean                 |\n",
    "| **Parameter Estimation**       | Mean and variance for each feature          | Feature probabilities based on counts       | Feature probabilities adjusted for imbalance | Feature probabilities for binary features   |\n",
    "| **Common Applications**        | Sensor data, real-valued data               | Text classification                         | Text classification with class imbalance    | Text classification with binary features    |\n",
    "| **Handling of Zero Counts**    | Not applicable                              | Smoothing (Laplace or other)                | Smoothing (Laplace or other)                | Smoothing (Laplace or other)                |\n",
    "| **Performance**                | Fast, handles continuous data well          | Fast, effective for text data               | Better for imbalanced text data             | Fast, effective for binary features         |\n",
    "| **Output**                     | Probability estimates                       | Probability estimates                       | Probability estimates                       | Probability estimates                       |\n",
    "| **Pros**                       | Handles continuous data, simple and fast    | Effective for text classification           | Better performance with imbalanced data     | Simple and effective for binary data        |\n",
    "| **Cons**                       | Assumes normal distribution of features     | Not suitable for continuous data            | More complex than MultinomialNB             | Not suitable for non-binary data            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian NB Accuracy: 0.7944\n",
      "Multinomial NB Accuracy: 0.7843\n",
      "Complement NB Accuracy: 0.7843\n",
      "Bernoulli NB Accuracy: 0.7855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "gnb = GaussianNB()\n",
    "y_test_gnb = gnb.fit(X_train, Y_train).predict(X_test)\n",
    "accuracy_gnb = accuracy_score(test_label, y_test_gnb)\n",
    "print(f'Gaussian NB Accuracy: {accuracy_gnb:.4f}')\n",
    "\n",
    "mtb = MultinomialNB()\n",
    "y_test_mtb = mtb.fit(X_train, Y_train).predict(X_test)\n",
    "accuracy_mtb = accuracy_score(test_label, y_test_mtb)\n",
    "print(f'Multinomial NB Accuracy: {accuracy_mtb:.4f}')\n",
    "\n",
    "cmb = ComplementNB()\n",
    "y_test_cmb = cmb.fit(X_train, Y_train).predict(X_test)\n",
    "accuracy_cmb = accuracy_score(test_label, y_test_cmb)\n",
    "print(f'Complement NB Accuracy: {accuracy_cmb:.4f}')\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "y_test_bnb = bnb.fit(X_train, Y_train).predict(X_test)\n",
    "accuracy_bnb = accuracy_score(test_label, y_test_bnb)\n",
    "print(f'Bernoulli NB Accuracy: {accuracy_bnb:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Classifiers\n",
    "The key of using nearest neighbor classifiers is to find the best k value or the best radius. This will delineate the clustering boundaries. However, in the case of Radius Neighbors Classifier there are outliers if the radius are set too small. In this case, we can only label the outliers, and the radius size is dependent on whether the data is standardized. The KNeighbors Classifier is more stable than the Radius Neighbors Classifier, and the accuracy is higher after standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.8021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_nn = scaler.fit_transform(X_train)\n",
    "X_test_nn = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.8340\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=80, \n",
    "    weights='uniform', \n",
    "    algorithm='auto', \n",
    "    leaf_size=30, \n",
    "    p=2, \n",
    "    metric='minkowski', \n",
    "    metric_params=None, \n",
    "    n_jobs=None\n",
    ")\n",
    "knn.fit(X_train_nn, Y_train)\n",
    "y_pred_knn = knn.predict(X_test_nn)\n",
    "\n",
    "accuracy = accuracy_score(test_label, y_pred_knn)\n",
    "print(f'KNN Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    26      4 256263 ...      0     25     39]\n",
      " [    24      4 170277 ...      0     35     39]\n",
      " [    36      4  75826 ...      0     40     39]\n",
      " ...\n",
      " [    55      6 238192 ...   1887     40     39]\n",
      " [    41      4 154076 ...      0     50     39]\n",
      " [    22      4 162667 ...      0     50     32]]\n",
      "[[-0.92195464  0.3589164   0.63253053 ... -0.21767954 -1.25838714\n",
      "   0.29317867]\n",
      " [-1.06915047  0.3589164  -0.18615485 ... -0.21767954 -0.44751661\n",
      "   0.29317867]\n",
      " [-0.18597545  0.3589164  -1.08543674 ... -0.21767954 -0.04208134\n",
      "   0.29317867]\n",
      " ...\n",
      " [ 1.212385    1.92256488  0.46047387 ...  4.42104086 -0.04208134\n",
      "   0.29317867]\n",
      " [ 0.18201414  0.3589164  -0.34040696 ... -0.21767954  0.76878919\n",
      "   0.29317867]\n",
      " [-1.21634631  0.3589164  -0.25861078 ... -0.21767954  0.76878919\n",
      "  -0.59454636]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radius Neighbors Accuracy: 0.8098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaredan/miniconda3/envs/CS311_proj3/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:763: UserWarning: Outlier label -1 is not in training classes. All class probabilities of outliers will be assigned with 0.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rnc = RadiusNeighborsClassifier(\n",
    "    radius=2.25, \n",
    "    weights='uniform', \n",
    "    algorithm='auto', \n",
    "    leaf_size=30, \n",
    "    p=2, \n",
    "    metric='minkowski', \n",
    "    outlier_label=-1, \n",
    "    metric_params=None, \n",
    "    n_jobs=None\n",
    ")\n",
    "rnc.fit(X_train_nn, Y_train)\n",
    "y_pred_rnc = rnc.predict(X_test_nn)\n",
    "\n",
    "accuracy = accuracy_score(test_label, y_pred_rnc)\n",
    "print(f'Radius Neighbors Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC, NuSVC, LinearSVC\n\u001b[1;32m      2\u001b[0m svc \u001b[38;5;241m=\u001b[39m SVC(\n\u001b[1;32m      3\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, \n\u001b[1;32m      4\u001b[0m     kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m svc\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, Y_train)\n\u001b[1;32m     20\u001b[0m y_pred_svc \u001b[38;5;241m=\u001b[39m svc\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     21\u001b[0m accuracy_svc \u001b[38;5;241m=\u001b[39m accuracy_score(test_label, y_pred_svc)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "svc = SVC(\n",
    "    C=1.0, \n",
    "    kernel='poly', \n",
    "    degree=3, \n",
    "    gamma='scale', \n",
    "    coef0=0.0, \n",
    "    shrinking=True, \n",
    "    probability=False, \n",
    "    tol=0.001, \n",
    "    cache_size=200, \n",
    "    class_weight=None, \n",
    "    verbose=False, \n",
    "    max_iter=-1, \n",
    "    decision_function_shape='ovr', \n",
    "    break_ties=False, \n",
    "    random_state=None\n",
    ")\n",
    "svc.fit(X_train, Y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "accuracy_svc = accuracy_score(test_label, y_pred_svc)\n",
    "print(f'SVC Accuracy: {accuracy_svc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
